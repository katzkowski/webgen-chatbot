{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "DATA_PATH = Path(os.getenv(\"DATA_PATH\"))\n",
    "\n",
    "\n",
    "# only for .ipynb because relative imports don't work\n",
    "root_path = Path(DATA_PATH).parent\n",
    "os.chdir(str(root_path))\n",
    "\n",
    "import src.database.db_connector as db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# database name for results\n",
    "db_name = \"clustering_db\"\n",
    "cnx = db.connect_to_database(db_name)\n",
    "# cursor = db.get_connection_cursor(cnx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get list of top n labels for each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top n labels for each cluster withj \n",
    "top_n_query = \"\"\"\n",
    "    SELECT rj.ranked_k_value, rj.cluster_id, rj.label_name, rj.factor_tf_idf\n",
    "    FROM ( \n",
    "        SELECT * FROM (\n",
    "            SELECT \n",
    "            j.ranked_k_value,\n",
    "            j.cluster_id, \n",
    "            @cluster_rank := if(@current_cluster = j.cluster_id, @cluster_rank  + 1, 1) AS cluster_rank ,\n",
    "            j.label_name,\n",
    "            j.factor_tf_idf,\n",
    "            @current_cluster := j.cluster_id\n",
    "            FROM ( \n",
    "                SELECT  *\n",
    "                FROM matchings AS m\n",
    "                INNER JOIN ( \n",
    "                    SELECT ma.k_value as ranked_k_value\n",
    "                    FROM matchings AS ma\n",
    "                    WHERE (ma.run_name = \"v01_all_run2_pca90\" OR ma.run_name = \"v01_all_run3_pca90\") \n",
    "                    group by ma.k_value\n",
    "                ) as ranked_k on ranked_k.ranked_k_value = m.k_value\n",
    "                WHERE (m.run_name = \"v01_all_run2_pca90\" OR m.run_name = \"v01_all_run3_pca90\")  AND m.k_value = ranked_k.ranked_k_value\n",
    "                ORDER BY ranked_k.ranked_k_value, m.cluster_id, m.factor_tf_idf desc\n",
    "            ) as j\n",
    "        ) as ranked_clusters\n",
    "        where ranked_clusters.cluster_rank <= 5\n",
    "    ) as rj;\n",
    "\"\"\"\n",
    "\n",
    "df_topn = pd.read_sql(top_n_query, cnx)\n",
    "print(df_topn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scores over top *n* values of each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_query = \"\"\"\n",
    "    SELECT rj.ranked_k_value, \n",
    "    AVG(rj.cluster_label_count),\n",
    "    AVG(rj.cluster_size),\n",
    "    AVG(rj.factor_tf_idf),\n",
    "    STD(rj.factor_tf_idf)\n",
    "    FROM ( \n",
    "        SELECT \n",
    "        ranked_clusters.cluster_id, \n",
    "        ranked_clusters.ranked_k_value, \n",
    "        c.n_screenshots as cluster_size,\n",
    "        ranked_clusters.cluster_label_count,\n",
    "        ranked_clusters.percentage,\n",
    "        ranked_clusters.factor,\n",
    "        ranked_clusters.tf,\n",
    "        ranked_clusters.idf,\n",
    "        ranked_clusters.tf_idf,\n",
    "        ranked_clusters.factor_tf_idf\n",
    "        FROM (\n",
    "            SELECT \n",
    "            j.ranked_run,\n",
    "            j.cluster_id,\n",
    "            j.ranked_k_value, \n",
    "            @cluster_rank := if(@current_cluster = j.cluster_id, @cluster_rank  + 1, 1) AS cluster_rank ,\n",
    "            j.label_name,\n",
    "            j.cluster_label_count,\n",
    "            j.percentage,\n",
    "            j.factor,\n",
    "            j.tf,\n",
    "            j.idf,\n",
    "            j.tf_idf,\n",
    "            j.factor_tf_idf,\n",
    "            @current_cluster := j.cluster_id\n",
    "            FROM ( \n",
    "                SELECT  *\n",
    "                FROM matchings AS m\n",
    "                INNER JOIN ( \n",
    "                    SELECT ma.k_value as ranked_k_value, ma.run_name as ranked_run\n",
    "                    FROM matchings AS ma\n",
    "                    WHERE (ma.run_name = \"v01_all_run2_pca90\" OR ma.run_name = \"v01_all_run3_pca90\") \n",
    "                    group by ma.k_value\n",
    "                ) as ranked_k on ranked_k.ranked_k_value = m.k_value\n",
    "                INNER JOIN labels as l on m.label_name = l.name\n",
    "                WHERE (m.run_name = \"v01_all_run2_pca90\" OR m.run_name = \"v01_all_run3_pca90\")  AND m.k_value = ranked_k.ranked_k_value AND l.type !=\"technology\"\n",
    "                ORDER BY ranked_k.ranked_k_value, m.cluster_id, m.factor_tf_idf desc\n",
    "            ) as j\n",
    "        ) as ranked_clusters\n",
    "        inner join clusters as c on c.k_value = ranked_clusters.ranked_k_value and c.cluster_id = ranked_clusters.cluster_id and ranked_clusters.ranked_run = c.run_name\n",
    "        where ranked_clusters.cluster_rank <= 5\n",
    "    ) as rj\n",
    "    GROUP BY rj.ranked_k_value;\n",
    "\"\"\"\n",
    "\n",
    "df_scores = pd.read_sql(scores_query, cnx)\n",
    "print(df_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot `factor_tf_idf` and cluster size regarding *k*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "fig, ax = plt.subplots(figsize=(18,6))\n",
    "\n",
    "x = df_scores[\"ranked_k_value\"]\n",
    "y_fac = df_scores[\"AVG(rj.factor_tf_idf)\"]\n",
    "error = np.array(df_scores[\"STD(rj.factor_tf_idf)\"])\n",
    "\n",
    "df_scores.plot(x=\"ranked_k_value\", y=\"AVG(rj.factor_tf_idf)\", label=\"Factor-LF-ILF\", legend=True, xlim=(10,200), ylim=(0.0, 1.0), ax=ax, xlabel=\"k\")\n",
    "ax.set_xticks(df_scores[\"ranked_k_value\"])\n",
    "\n",
    "# avg factor_tf_id with std as error zone\n",
    "ax.fill_between(x, y_fac - (error/2), y_fac + (error/2), alpha=0.1)\n",
    "\n",
    "# cluster size\n",
    "df_scores.plot(x=\"ranked_k_value\", y=\"AVG(rj.cluster_size)\", secondary_y=True, label=\"Cluster size\", legend=True, ax=ax, xlabel=\"k\")\n",
    "\n",
    "# add grid to x-axis\n",
    "ax.xaxis.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IDF scores for each k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_query = \"\"\"\n",
    "    select b.k, avg(b.idf_s) FROM\n",
    "(\n",
    "\tSelect *,  idf(a.uniq_cnt, a.k) as idf_s \n",
    "\tFROM (\n",
    "\t\tSELECT rj.ranked_k_value as k, rj.cluster_id, rj.label_name, count(rj.label_name) as uniq_cnt\n",
    "\t\tFROM ( \n",
    "\t\t\tSELECT * FROM (\n",
    "\t\t\t\tSELECT \n",
    "\t\t\t\tj.ranked_k_value,\n",
    "\t\t\t\tj.cluster_id, \n",
    "\t\t\t\t@cluster_rank := if(@current_cluster = j.cluster_id, @cluster_rank  + 1, 1) AS cluster_rank ,\n",
    "\t\t\t\tj.label_name,\n",
    "\t\t\t\tj.factor_tf_idf,\n",
    "\t\t\t\t@current_cluster := j.cluster_id\n",
    "\t\t\t\tFROM ( \n",
    "\t\t\t\t\tSELECT  *\n",
    "\t\t\t\t\tFROM matchings AS m\n",
    "\t\t\t\t\tINNER JOIN ( \n",
    "\t\t\t\t\t\tSELECT ma.k_value as ranked_k_value\n",
    "\t\t\t\t\t\tFROM matchings AS ma\n",
    "\t\t\t\t\t\tWHERE (ma.run_name = \"v01_all_run2_pca90\" OR ma.run_name = \"v01_all_run3_pca90\") \n",
    "\t\t\t\t\t\tgroup by ma.k_value\n",
    "\t\t\t\t\t) as ranked_k on ranked_k.ranked_k_value = m.k_value\n",
    "\t\t\t\t\tWHERE (m.run_name = \"v01_all_run2_pca90\" OR m.run_name = \"v01_all_run3_pca90\")  AND m.k_value = ranked_k.ranked_k_value\n",
    "\t\t\t\t\tORDER BY ranked_k.ranked_k_value, m.cluster_id, m.factor_tf_idf desc\n",
    "\t\t\t\t) as j\n",
    "\t\t\t) as ranked_clusters\n",
    "\t\t\twhere ranked_clusters.cluster_rank > 0\n",
    "\t\t) as rj\n",
    "\t\tGROUP BY rj.ranked_k_value, rj.label_name\n",
    "\t) as a\n",
    "\tORDER BY a.k\n",
    ") as b\n",
    "Group by b.k;\n",
    "\"\"\"\n",
    "\n",
    "df_op = pd.read_sql(op_query, cnx)\n",
    "print(df_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "fig, ax = plt.subplots(figsize=(18,6))\n",
    "\n",
    "x = df_op[\"k\"]\n",
    "y_fac = df_op[\"avg(b.idf_s)\"]\n",
    "# error = np.array(df_scores[\"STD(rj.factor_tf_idf)\"])\n",
    "\n",
    "df_op.plot(x=\"k\", y=\"avg(b.idf_s)\", label=\"avg(b.idf_s)\", legend=True, xlim=(10,200), ylim=(0.0, 2.0), ax=ax)\n",
    "ax.set_xticks(df_op[\"k\"])\n",
    "\n",
    "# avg factor_tf_id with std as error zone\n",
    "# ax.fill_between(x, y_fac - (error/2), y_fac + (error/2), alpha=0.1)\n",
    "\n",
    "# cluster size\n",
    "df_scores.plot(x=\"ranked_k_value\", y=\"AVG(rj.cluster_size)\", secondary_y=True, label=\"cluster size\", legend=True, ax=ax)\n",
    "\n",
    "# add grid to x-axis\n",
    "ax.xaxis.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique Labels Ratio for each k in top 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_label_ratios = []\n",
    "\n",
    "for k_value in range(10, 201, 5):\n",
    "\n",
    "    k_query = f\"\"\"\n",
    "        SELECT rj.label_name\n",
    "        FROM ( \n",
    "            SELECT * FROM (\n",
    "                SELECT \n",
    "                j.ranked_k_value,\n",
    "                j.cluster_id, \n",
    "                @cluster_rank := if(@current_cluster = j.cluster_id, @cluster_rank  + 1, 1) AS cluster_rank ,\n",
    "                j.label_name,\n",
    "                j.factor_tf_idf,\n",
    "                @current_cluster := j.cluster_id\n",
    "                FROM ( \n",
    "                    SELECT  *\n",
    "                    FROM matchings AS m\n",
    "                    INNER JOIN ( \n",
    "                        SELECT ma.k_value as ranked_k_value\n",
    "                        FROM matchings AS ma\n",
    "                        WHERE (ma.run_name = \"v01_all_run2_pca90\" OR ma.run_name = \"v01_all_run3_pca90\") AND ma.k_value={str(k_value)} \n",
    "                        group by ma.k_value\n",
    "                    ) as ranked_k on ranked_k.ranked_k_value = m.k_value\n",
    "                    WHERE (m.run_name = \"v01_all_run2_pca90\" OR m.run_name = \"v01_all_run3_pca90\")  AND m.k_value = ranked_k.ranked_k_value\n",
    "                    ORDER BY ranked_k.ranked_k_value, m.cluster_id, m.factor_tf_idf desc\n",
    "                ) as j\n",
    "            ) as ranked_clusters\n",
    "            where ranked_clusters.cluster_rank <= 5\n",
    "        ) as rj;\n",
    "    \"\"\"\n",
    "\n",
    "    k_df = pd.read_sql(k_query, cnx)\n",
    "    unique_count = len(np.unique(k_df.values))\n",
    "    total_count = len(k_df.values)\n",
    "    unique_label_ratios.append((k_value,  (unique_count / total_count)))\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18,6))\n",
    "\n",
    "x = [tpl[0] for tpl in unique_label_ratios]\n",
    "y = [tpl[1] for tpl in unique_label_ratios]\n",
    "\n",
    "plt.xticks(x)\n",
    "plt.ylim(0,1)\n",
    "plt.plot(x,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WSS + Sil Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.clustering.kmeans as km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "args = [\n",
    "    \"v01_all\",\n",
    "    \"wss_sil_eval_1\",\n",
    "    \"10\",\n",
    "    \"200\",\n",
    "    \"5\",\n",
    "    \"0.9\"\n",
    "]\n",
    "\n",
    "list_k, sse, sil = km.run_training(args)\n",
    "print(list_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store sse + sil in .csv file\n",
    "df_kmeans = pd.DataFrame({\"k\": list_k, \"sse\": sse, \"sil\": sil})\n",
    "print(df_kmeans)\n",
    "\n",
    "df_kmeans.to_csv(DATA_PATH / \"extracted_features\" / \"clustering_sse_wss.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sse)\n",
    "fig, ax = plt.subplots(figsize=(18,6))\n",
    "plt.xticks(list_k)\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Sum of Squared Errors\")\n",
    "plt.gca().xaxis.grid(True)\n",
    "plt.plot(list_k,sse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(18,6))\n",
    "plt.xticks(list_k)\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"Silhoette Score\")\n",
    "plt.gca().xaxis.grid(True)\n",
    "plt.plot(list_k,sil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Calculate Real IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_count_query = \"\"\"\n",
    "    SELECT m.label_name, Count(m.cluster_id) as cluster_count FROM clustering_db.matchings m\n",
    "    inner join labels l on m.label_name=l.name\n",
    "    where m.k_value=%s and l.type != \"technology\"\n",
    "    group by m.label_name;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avgs = []\n",
    "stds = []\n",
    "\n",
    "for k in range(10, 201, 5):\n",
    "    # count cluster occurrences for each label (term)\n",
    "    df_cc_k = pd.read_sql(cluster_count_query, cnx, params=[k])\n",
    "\n",
    "    # calculate average occurrences + std error\n",
    "    avg_cc = df_cc_k[\"cluster_count\"].mean()\n",
    "    std_cc = df_cc_k[\"cluster_count\"].std()\n",
    "    \n",
    "    avgs.append(avg_cc)\n",
    "    stds.append(std_cc)\n",
    "\n",
    "print(avgs)\n",
    "print(stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "\n",
    "# k's\n",
    "x = list(range(10,201,5))\n",
    "\n",
    "# 1 + idf score based on average count\n",
    "y = [ math.log10(k / elem) for elem, k in zip(avgs, x)]\n",
    "\n",
    "# upper bound error: 1 + idf(avg + std)\n",
    "error_upper = np.array([math.log10(k / (a + s)) for s, a, k in zip(stds, avgs, x)])\n",
    "\n",
    "# lower bound error: 1 + idf(avg - std)\n",
    "error_lower = np.array([math.log10(k/ (a - s)) for s, a, k in zip(stds, avgs, x)])\n",
    "\n",
    "\n",
    "# plot error zone\n",
    "plt.fill_between(x, error_upper, error_lower, alpha=0.1)\n",
    "\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylabel(\"ICF\")\n",
    "\n",
    "plt.xticks([10,25,50,75,100,125,150,175,200])\n",
    "plt.ylim(-0.2,0.2)\n",
    "plt.gca().xaxis.grid(True)\n",
    "plt.plot(x,y)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "07e3a7355d7abb8aa405eb35da3e7fd4ab2bc4b84e1079a2d318e7f47c8b0cf5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
